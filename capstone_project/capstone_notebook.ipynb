{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Project Title\n",
    "### Data Engineering Capstone Project\n",
    "\n",
    "#### Project Summary\n",
    "In the scope of this project we investigate a dataset called US I94 about immigration under consideration of further data about demographics and temperature for a more comprehensive analysis of causes of immigration. We extract transform the data from different sources and load it into a data model using a star schema with a central fact table. The purpose of the generated data model is to allow an comprehensive analysis of the immigration to the United States under consideration of demographics and temperature. The model should furthermore be extenable with additional data.\n",
    "\n",
    "The project follows the follow steps:\n",
    "1. Loading of data\n",
    "2. Exploration and cleaning of data\n",
    "3. Definition of data model\n",
    "4. Loading of data into model\n",
    "5. Quality checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "In the scope of this project we investigate a dataset called US I94 about immigration under consideration of further data about demographics and temperature for a more comprehensive analysis of causes of immigration.\n",
    "\n",
    "#### Describe and Gather Data \n",
    "We use data from four different datasets:\n",
    "\n",
    "- I94 Immigration Data: This data comes from the [US National Tourism and Trade Office](https://www.trade.gov/national-travel-and-tourism-office); it includes information about immigrants and their departure airport. \n",
    "- World Temperature Data: This dataset came from [Kaggle](https://www.kaggle.com/berkeleyearth/climate-change-earth-surface-temperature-data); contains information about surface temperature of countries in the world.\n",
    "- U.S. City Demographic Data: This data comes from [OpenSoft](https://public.opendatasoft.com/explore/dataset/us-cities-demographics/export/); contains information about the demographics of all US cities and census-designated places with a population greater or equal to 65,000. \n",
    "- Airport Code Table: This is a simple table of IATA airport codes and corresponding cities. Comes from [datahub.io](https://datahub.io/core/airport-codes#data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Read in all datasets with Pyspark for faster use and sample with pandas and SQL temp view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"PATH\"] = \"/opt/conda/bin:/opt/spark-2.4.3-bin-hadoop2.7/bin:/opt/conda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/lib/jvm/java-8-openjdk-amd64/bin\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "os.environ[\"HADOOP_HOME\"] = \"/opt/spark-2.4.3-bin-hadoop2.7\"\n",
    "\n",
    "# Create Spark Session\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Read in datasets\n",
    "\n",
    "# I94\n",
    "immigrations_spark =spark.read.load('./sas_data')\n",
    "immigrations_df = immigrations_spark.limit(500).toPandas()\n",
    "\n",
    "immigrations_spark.createOrReplaceTempView('immigrations')\n",
    "\n",
    "# Airports\n",
    "airports_spark = spark.read.option(\"header\",True).csv(\"airport-codes_csv.csv\")\n",
    "airports_df = airports_spark.limit(500).toPandas()\n",
    "\n",
    "airports_spark.createOrReplaceTempView('airports')\n",
    "\n",
    "# us-cities-demographics\n",
    "us_demographics_spark = spark.read.option(\"header\",True).option(\"delimiter\", ';').csv(\"us-cities-demographics.csv\")\n",
    "us_demographics_df = us_demographics_spark.limit(500).toPandas()\n",
    "\n",
    "us_demographics_spark.createOrReplaceTempView('us_demographics')\n",
    "\n",
    "# city temperatures\n",
    "city_temperatures_spark = spark.read.option(\"header\",True).csv('../../data2/GlobalLandTemperaturesByCity.csv')\n",
    "city_temperatures_df = city_temperatures_spark.limit(500).toPandas()\n",
    "\n",
    "city_temperatures_spark.createOrReplaceTempView('city_temperatures')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
      "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
      "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
      "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
      "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
      "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
      "\n",
      "  i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
      "0      CA  20582.0   ...        None        M   1976.0  10292016      F   \n",
      "1      NV  20591.0   ...        None        M   1984.0  10292016      F   \n",
      "2      WA  20582.0   ...        None        M   1987.0  10292016      M   \n",
      "3      WA  20588.0   ...        None        M   1987.0  10292016      F   \n",
      "4      WA  20588.0   ...        None        M   1988.0  10292016      M   \n",
      "\n",
      "  insnum airline        admnum  fltno visatype  \n",
      "0   None      QF  9.495387e+10  00011       B1  \n",
      "1   None      VA  9.495562e+10  00007       B1  \n",
      "2   None      DL  9.495641e+10  00040       B1  \n",
      "3   None      DL  9.495645e+10  00040       B1  \n",
      "4   None      DL  9.495639e+10  00040       B1  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "Index(['cicid', 'i94yr', 'i94mon', 'i94cit', 'i94res', 'i94port', 'arrdate',\n",
      "       'i94mode', 'i94addr', 'depdate', 'i94bir', 'i94visa', 'count',\n",
      "       'dtadfile', 'visapost', 'occup', 'entdepa', 'entdepd', 'entdepu',\n",
      "       'matflag', 'biryear', 'dtaddto', 'gender', 'insnum', 'airline',\n",
      "       'admnum', 'fltno', 'visatype'],\n",
      "      dtype='object')\n",
      "  ident           type                                name elevation_ft  \\\n",
      "0   00A       heliport                   Total Rf Heliport           11   \n",
      "1  00AA  small_airport                Aero B Ranch Airport         3435   \n",
      "2  00AK  small_airport                        Lowell Field          450   \n",
      "3  00AL  small_airport                        Epps Airpark          820   \n",
      "4  00AR         closed  Newport Hospital & Clinic Heliport          237   \n",
      "\n",
      "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
      "0        NA          US      US-PA      Bensalem      00A      None   \n",
      "1        NA          US      US-KS         Leoti     00AA      None   \n",
      "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
      "3        NA          US      US-AL       Harvest     00AL      None   \n",
      "4        NA          US      US-AR       Newport     None      None   \n",
      "\n",
      "  local_code                            coordinates  \n",
      "0        00A     -74.93360137939453, 40.07080078125  \n",
      "1       00AA                 -101.473911, 38.704022  \n",
      "2       00AK            -151.695999146, 59.94919968  \n",
      "3       00AL  -86.77030181884766, 34.86479949951172  \n",
      "4       None                    -91.254898, 35.6087  \n",
      "Index(['ident', 'type', 'name', 'elevation_ft', 'continent', 'iso_country',\n",
      "       'iso_region', 'municipality', 'gps_code', 'iata_code', 'local_code',\n",
      "       'coordinates'],\n",
      "      dtype='object')\n",
      "               City          State Median Age Male Population  \\\n",
      "0     Silver Spring       Maryland       33.8           40601   \n",
      "1            Quincy  Massachusetts       41.0           44129   \n",
      "2            Hoover        Alabama       38.5           38040   \n",
      "3  Rancho Cucamonga     California       34.5           88127   \n",
      "4            Newark     New Jersey       34.6          138040   \n",
      "\n",
      "  Female Population Total Population Number of Veterans Foreign-born  \\\n",
      "0             41862            82463               1562        30908   \n",
      "1             49500            93629               4147        32935   \n",
      "2             46799            84839               4819         8229   \n",
      "3             87105           175232               5821        33878   \n",
      "4            143873           281913               5829        86253   \n",
      "\n",
      "  Average Household Size State Code                       Race  Count  \n",
      "0                    2.6         MD         Hispanic or Latino  25924  \n",
      "1                   2.39         MA                      White  58723  \n",
      "2                   2.58         AL                      Asian   4759  \n",
      "3                   3.18         CA  Black or African-American  24437  \n",
      "4                   2.73         NJ                      White  76402  \n",
      "Index(['City', 'State', 'Median Age', 'Male Population', 'Female Population',\n",
      "       'Total Population', 'Number of Veterans', 'Foreign-born',\n",
      "       'Average Household Size', 'State Code', 'Race', 'Count'],\n",
      "      dtype='object')\n",
      "           dt AverageTemperature AverageTemperatureUncertainty   City  \\\n",
      "0  1743-11-01              6.068            1.7369999999999999  Århus   \n",
      "1  1743-12-01               None                          None  Århus   \n",
      "2  1744-01-01               None                          None  Århus   \n",
      "3  1744-02-01               None                          None  Århus   \n",
      "4  1744-03-01               None                          None  Århus   \n",
      "\n",
      "   Country Latitude Longitude  \n",
      "0  Denmark   57.05N    10.33E  \n",
      "1  Denmark   57.05N    10.33E  \n",
      "2  Denmark   57.05N    10.33E  \n",
      "3  Denmark   57.05N    10.33E  \n",
      "4  Denmark   57.05N    10.33E  \n",
      "Index(['dt', 'AverageTemperature', 'AverageTemperatureUncertainty', 'City',\n",
      "       'Country', 'Latitude', 'Longitude'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df_list = [immigrations_df, airports_df, us_demographics_df, city_temperatures_df]\n",
    "\n",
    "for dataset in df_list:\n",
    "    print(dataset.head(5))\n",
    "    print(dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 2: Explore and Assess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### City Temperatures\n",
    "\n",
    "Exploring:\n",
    "- Table contains temperature measurements for cities at different time stamps\n",
    "- Many Null values for the temperatures that need to be removed\n",
    "\n",
    "Clearning:\n",
    "- For city_temperatures we get all rows for data form the United States that is not null, convert the string date to datetime and drop the dublicates and drop rows with any nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>AverageTemperature</th>\n",
       "      <th>AverageTemperatureUncertainty</th>\n",
       "      <th>City</th>\n",
       "      <th>Country</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1743-11-01</td>\n",
       "      <td>6.068</td>\n",
       "      <td>1.7369999999999999</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1743-12-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1744-01-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1744-02-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1744-03-01</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Århus</td>\n",
       "      <td>Denmark</td>\n",
       "      <td>57.05N</td>\n",
       "      <td>10.33E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt AverageTemperature AverageTemperatureUncertainty   City  \\\n",
       "0  1743-11-01              6.068            1.7369999999999999  Århus   \n",
       "1  1743-12-01               None                          None  Århus   \n",
       "2  1744-01-01               None                          None  Århus   \n",
       "3  1744-02-01               None                          None  Århus   \n",
       "4  1744-03-01               None                          None  Århus   \n",
       "\n",
       "   Country Latitude Longitude  \n",
       "0  Denmark   57.05N    10.33E  \n",
       "1  Denmark   57.05N    10.33E  \n",
       "2  Denmark   57.05N    10.33E  \n",
       "3  Denmark   57.05N    10.33E  \n",
       "4  Denmark   57.05N    10.33E  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_temperatures_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from clean_data import clean_city_temperatures, clean_us_demographics, clean_airports, clean_immigrations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+--------+---------+------------------+-----------------------------+----------+\n",
      "| City|Country|Latitude|Longitude|AverageTemperature|AverageTemperatureUncertainty|        dt|\n",
      "+-----+-------+--------+---------+------------------+-----------------------------+----------+\n",
      "|Århus|Denmark|  57.05N|   10.33E|            16.824|                         3.62|1771-06-01|\n",
      "|Århus|Denmark|  57.05N|   10.33E|            -6.918|                        7.193|1776-01-01|\n",
      "|Århus|Denmark|  57.05N|   10.33E|            12.606|                        2.666|1790-05-01|\n",
      "|Århus|Denmark|  57.05N|   10.33E|            16.656|                        2.203|1792-08-01|\n",
      "|Århus|Denmark|  57.05N|   10.33E|             1.309|                        3.533|1803-03-01|\n",
      "+-----+-------+--------+---------+------------------+-----------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "city_temperatures_spark_cleaned = clean_city_temperatures(city_temperatures_spark, spark)\n",
    "city_temperatures_spark_cleaned.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### US demographics\n",
    "\n",
    "Exploring:\n",
    "- We have multiple rows for a city since counts are given for different races, these values need to be pivoted\n",
    "\n",
    "Clearning:\n",
    "- For us_demographics we drop dublicates and rows with nulls, we then pivot the Race column and add 0 for missing race counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+-----+\n",
      "|City   |State|Median Age|Male Population|Female Population|Total Population|Number of Veterans|Foreign-born|Average Household Size|State Code|Race                             |Count|\n",
      "+-------+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+-----+\n",
      "|Abilene|Texas|31.3      |65212          |60664            |125876          |9367              |8129        |2.64                  |TX        |Asian                            |2929 |\n",
      "|Abilene|Texas|31.3      |65212          |60664            |125876          |9367              |8129        |2.64                  |TX        |Hispanic or Latino               |33222|\n",
      "|Abilene|Texas|31.3      |65212          |60664            |125876          |9367              |8129        |2.64                  |TX        |American Indian and Alaska Native|1813 |\n",
      "|Abilene|Texas|31.3      |65212          |60664            |125876          |9367              |8129        |2.64                  |TX        |Black or African-American        |14449|\n",
      "|Abilene|Texas|31.3      |65212          |60664            |125876          |9367              |8129        |2.64                  |TX        |White                            |95487|\n",
      "+-------+-----+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_demographics_spark.orderBy(['City','State']).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|     State|   City|Median_Age|Male_Population|Female_Population|Total_Population|Number_of_Veterans|Foregin_born|Average_Household_Size|State_Code|American_Indian_and_Alaska_Native|Asian|Black_or_African_American|Hispanic_or_Latino| White|\n",
      "+----------+-------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "|     Texas|Abilene|      31.3|          65212|            60664|          125876|              9367|        8129|                  2.64|        TX|                             1813| 2929|                    14449|             33222| 95487|\n",
      "|      Ohio|  Akron|      38.1|          96886|           100667|          197553|             12878|       10024|                  2.24|        OH|                             1845| 9033|                    66551|              3684|129192|\n",
      "|   Florida|Alafaya|      33.5|          39504|            45760|           85264|              4176|       15842|                  2.94|        FL|                                0|10336|                     6577|             34897| 63666|\n",
      "|California|Alameda|      41.4|          37747|            40867|           78614|              4504|       18841|                  2.52|        CA|                             1329|27984|                     7364|              8265| 44232|\n",
      "|   Georgia| Albany|      33.3|          31695|            39414|           71109|              5409|         861|                  2.38|        GA|                              445|  650|                    53440|              1783| 17160|\n",
      "+----------+-------+----------+---------------+-----------------+----------------+------------------+------------+----------------------+----------+---------------------------------+-----+-------------------------+------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "us_demographics_spark_cleaned = clean_us_demographics(us_demographics_spark, spark)\n",
    "us_demographics_spark_cleaned.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Airports\n",
    "\n",
    "Exploring:\n",
    "- Contains data from multiple airports, only international ones with IATA code are interessting\n",
    "\n",
    "Cleaning:\n",
    "- For airports we get only airports with a IATA code, again dublicates and rows with Null are droped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>None</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>None</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>None</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>None</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237</td>\n",
       "      <td>NA</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport           11   \n",
       "1  00AA  small_airport                Aero B Ranch Airport         3435   \n",
       "2  00AK  small_airport                        Lowell Field          450   \n",
       "3  00AL  small_airport                        Epps Airpark          820   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport          237   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0        NA          US      US-PA      Bensalem      00A      None   \n",
       "1        NA          US      US-KS         Leoti     00AA      None   \n",
       "2        NA          US      US-AK  Anchor Point     00AK      None   \n",
       "3        NA          US      US-AL       Harvest     00AL      None   \n",
       "4        NA          US      US-AR       Newport     None      None   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4       None                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airports_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+-----------+-----+---------+\n",
      "| ident|               name|       City|State|iata_code|\n",
      "+------+-------------------+-----------+-----+---------+\n",
      "|  AYWF|Wawoi Falls Airport|Wavoi Falls|  WPD|      WAJ|\n",
      "|  BIRF|        Rif Airport|        Rif|    3|      OLI|\n",
      "|BZ-CYC|Caye Chapel Airport|Caye Chapel|   BZ|      CYC|\n",
      "|   CGA|Craig Seaplane Base|      Craig|   AK|      CGA|\n",
      "|  CNT3| Ogoki Post Airport| Ogoki Post|   ON|      YOG|\n",
      "+------+-------------------+-----------+-----+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "airports_spark_cleaned = clean_airports(airports_spark, spark)\n",
    "airports_spark_cleaned.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Immigrations\n",
    "\n",
    "Exploring:\n",
    "- Colume names need to be renamed with understanable, intuitive names\n",
    "- arrival and departure date need to be converted to actual date with the 01.01.1960 as base date\n",
    "- Only rows with meaningful values should be selected\n",
    "- Need to add City as additional foregin key\n",
    "\n",
    "Clearning:\n",
    "- We convert arrival and departure date in dates, rename and select meaningful columns and drop dublicates and rows with Null values\n",
    "- Merge with airports data on iata_code to get city as column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5748517.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>QF</td>\n",
       "      <td>9.495387e+10</td>\n",
       "      <td>00011</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5748518.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NV</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>VA</td>\n",
       "      <td>9.495562e+10</td>\n",
       "      <td>00007</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5748519.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20582.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495641e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5748520.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495645e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5748521.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>LOS</td>\n",
       "      <td>20574.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>WA</td>\n",
       "      <td>20588.0</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>10292016</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>DL</td>\n",
       "      <td>9.495639e+10</td>\n",
       "      <td>00040</td>\n",
       "      <td>B1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode  \\\n",
       "0  5748517.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "1  5748518.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "2  5748519.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "3  5748520.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "4  5748521.0  2016.0     4.0   245.0   438.0     LOS  20574.0      1.0   \n",
       "\n",
       "  i94addr  depdate   ...     entdepu  matflag  biryear   dtaddto gender  \\\n",
       "0      CA  20582.0   ...        None        M   1976.0  10292016      F   \n",
       "1      NV  20591.0   ...        None        M   1984.0  10292016      F   \n",
       "2      WA  20582.0   ...        None        M   1987.0  10292016      M   \n",
       "3      WA  20588.0   ...        None        M   1987.0  10292016      F   \n",
       "4      WA  20588.0   ...        None        M   1988.0  10292016      M   \n",
       "\n",
       "  insnum airline        admnum  fltno visatype  \n",
       "0   None      QF  9.495387e+10  00011       B1  \n",
       "1   None      VA  9.495562e+10  00007       B1  \n",
       "2   None      DL  9.495641e+10  00040       B1  \n",
       "3   None      DL  9.495645e+10  00040       B1  \n",
       "4   None      DL  9.495639e+10  00040       B1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "immigrations_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+-----+---------+---------+------+-----+-------+---------+------+----------+-------+--------+--------+-------------+------------+--------------+\n",
      "|city_id|year|month|iata_code|city_code|res_id|State|matflag|birthyear|gender|   dtaddto|airline|visatype|visapost|flight_number|arrival_date|departure_date|\n",
      "+-------+----+-----+---------+---------+------+-----+-------+---------+------+----------+-------+--------+--------+-------------+------------+--------------+\n",
      "|6063613|2016|    4|      AGA|      268|   268|   GU|      M|     1988|     M|2016-12-06|     CI|     GMT|     TAI|        00026|  2016-04-29|    2016-05-03|\n",
      "| 473260|2016|    4|      SFR|      135|   135|   CA|      M|     1962|     M|2016-02-10|     SQ|      B2|     HNK|        00002|  2016-04-03|    2016-04-08|\n",
      "| 474080|2016|    4|      TAM|      135|   135|   FL|      M|     1958|     M|2016-02-10|     BA|      B2|     LND|        02167|  2016-04-03|    2016-05-09|\n",
      "| 474838|2016|    4|      HAM|      135|   509|   NY|      M|     1956|     M|2016-02-10|     DL|      B2|     HML|        01773|  2016-04-03|    2016-04-10|\n",
      "| 482067|2016|    4|      ATL|      148|   112|   NE|      M|     1969|     M|2016-02-10|     DL|      B1|     FRN|        00015|  2016-04-03|    2016-04-15|\n",
      "+-------+----+-----+---------+---------+------+-----+-------+---------+------+----------+-------+--------+--------+-------------+------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "immigrations_spark_cleaned = clean_immigrations(immigrations_spark, spark)\n",
    "immigrations_spark_cleaned.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Join immigrations and airports on iata_code\n",
    "\n",
    "airports_sec = airports_spark_cleaned.select(['iata_code', 'City'])\n",
    "airports_sec = airports_sec.withColumnRenamed('iata_code', 'iata_code_air')\n",
    "immigrations_spark_cleaned = immigrations_spark_cleaned.join(airports_sec, immigrations_spark_cleaned.iata_code == airports_sec.iata_code_air, 'left').select('*')\n",
    "immigrations_spark_cleaned = immigrations_spark_cleaned.drop('iata_code_air')\n",
    "\n",
    "airports_spark_cleaned = airports_spark_cleaned.drop('City')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "We use 4 tables with a star schema 3 dimension tables (city_temperature, airports, us_demographics) and the immigrations as fact table, see table below\n",
    "\n",
    "|Table |Columns  | Table kind| Foregin keys| Description|\n",
    "--- | --- | --- | --- | ---\n",
    "|city_temperature|City, Country, Latitude, Longitude, AverageTemperature, AverageTemperatureUncertainty, dt| Dimension table| City| temperature information from cities in different countries|\n",
    "|airports|ident, name, State, iata_code| Dimension table| iata_code| airport information|\n",
    "|us_demographics|State, City, Median_Age, Male_Population, Female_Population, Total_Population, Number_of_Veterans, Foreign_born, Average_Household_Size, State_Code, American_Indian_and_Alaska Native, Asian, Black_or_African_American, Hispanic_or_Latino, White| Dimension table City| City| demographics information|\n",
    "|immigratins|city_id, year,month, iata_code, city_code, res_id, State, matflag, birthyear, gender, dtaddto,  airline, visatype, visapost, flight_number, arrival_date, departure_date| Fact table| City| immigration information|\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import shutil\n",
    "from create_tables import create_tables, delete_tables\n",
    "\n",
    "conn = psycopg2.connect(\"host=127.0.0.1 dbname=studentdb user=student password=student\")\n",
    "conn.set_session(autocommit=True)\n",
    "conn.set_client_encoding('UTF8')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Drop Tables\n",
    "for delete_table in delete_tables:\n",
    "    try:\n",
    "        cur.execute(delete_table)\n",
    "    except:\n",
    "        print(f\"Table with query {create_table} could not be dropped\")\n",
    "        \n",
    "# Create Tables\n",
    "for create_table in create_tables:\n",
    "    try:\n",
    "        cur.execute(create_table)\n",
    "    except:\n",
    "        print(f\"Table with query {create_table} could not created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing city_temperatures to csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "city_temperatures processed: 100%|██████████| 200/200 [01:39<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing airports to csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "airports processed: 100%|██████████| 200/200 [00:00<00:00, 586.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing us_demographics to csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "us_demographics processed: 100%|██████████| 200/200 [00:00<00:00, 597.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing immigrations to csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "immigrations processed: 100%|██████████| 200/200 [00:02<00:00, 83.25it/s]\n"
     ]
    }
   ],
   "source": [
    "# write tables to csv\n",
    "spark_tables = [city_temperatures_spark_cleaned, airports_spark_cleaned, us_demographics_spark_cleaned, immigrations_spark_cleaned]\n",
    "table_names = ['city_temperatures','airports','us_demographics', 'immigrations']\n",
    "\n",
    "for table_name, spark_table in zip(table_names, spark_tables):\n",
    "    print(f'Writing {table_name} to csv')\n",
    "    shutil.rmtree(f'csv/{table_name}', ignore_errors=True)\n",
    "    spark_table.write.option(\"sep\", \";\").csv(f\"csv/{table_name}\")\n",
    "    \n",
    "    csv_list = [f for f in os.listdir(f\"csv/{table_name}\") if '.csv' in f and '.crc' not in f]\n",
    "    pbar = tqdm(csv_list)\n",
    "    for f in pbar:\n",
    "        pbar.set_description(f'{table_name} processed')\n",
    "        with open(f'csv/{table_name}/'+f, 'r', encoding=\"utf-8\") as file_in:\n",
    "            next(file_in)\n",
    "            columns = spark_table.schema.names\n",
    "            try:\n",
    "                cur.copy_from(file_in, table_name, columns=columns, sep=\";\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                \n",
    "shutil.rmtree(f'csv', ignore_errors=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "from check_quality import check_row_number, check_dtypes, check_column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quality check for city_temperatures successfull\n",
      "Quality check for airports successfull\n",
      "Quality check for us_demographics successfull\n",
      "Quality check for immigrations successfull\n",
      "Successfal column names test for city_temperatures\n",
      "Successfal column names test for airports\n",
      "Successfal column names test for us_demographics\n",
      "Successfal column names test for immigrations\n",
      "Successfal data types test for city_temperatures\n",
      "Successfal data types test for airports\n",
      "Successfal data types test for us_demographics\n",
      "Successfal data types test for immigrations\n"
     ]
    }
   ],
   "source": [
    "# Check number of rows / tables not to be empty\n",
    "check_row_number(cur, table_names)\n",
    "\n",
    "# Check column names of tables\n",
    "column_dict = {\n",
    "    'city_temperatures':['city', 'country', 'latitude', 'longitude', 'averagetemperature', 'averagetemperatureuncertainty', 'dt'],\n",
    "    'airports':['ident', 'name', 'state', 'iata_code'],\n",
    "    'us_demographics':['state', 'city', 'median_age', 'male_population', 'female_population', 'total_population', 'number_of_veterans', 'foregin_born', 'average_household_size', 'state_code', 'american_indian_and_alaska_native', 'asian', 'black_or_african_american', 'hispanic_or_latino', 'white'],\n",
    "    'immigrations':['city_id', 'year', 'month', 'iata_code', 'city_code', 'res_id', 'state', 'matflag', 'birthyear', 'gender', 'dtaddto', 'visatype', 'visapost', 'flight_number', 'airline', 'arrival_date', 'departure_date', 'city']\n",
    "}\n",
    "\n",
    "check_column_names(cur, table_names, column_dict)\n",
    "\n",
    "dtypes_dict = {\n",
    "    'city_temperatures':['character varying', 'character varying', 'character varying', 'character varying', 'double precision', 'double precision', 'date'],\n",
    "    'airports':['character varying', 'character varying', 'character varying', 'character varying'],\n",
    "    'us_demographics':['character varying', 'character varying', 'double precision', 'integer', 'integer', 'integer', 'integer', 'integer', 'double precision', 'character varying', 'integer', 'integer', 'integer', 'integer', 'character varying'],\n",
    "    'immigrations':['integer', 'integer', 'integer', 'character varying', 'integer', 'integer', 'character varying', 'character varying', 'integer', 'character varying', 'date', 'character varying', 'character varying', 'character varying', 'character varying', 'date', 'date', 'character varying'],\n",
    "}\n",
    "\n",
    "check_dtypes(cur, table_names, dtypes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. You can include the data dictionary in the notebook or in a separate file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## city_temperatures\n",
    "    |-- City: string (nullable = false) - city name from city_temperatures --FOREGIN KEY\n",
    "    |-- Country: string (nullable = false) - country name from city_temperatures\n",
    "    |-- Latitude: string (nullable = false) - latitude of city name from city_temperatures\n",
    "    |-- Longitude: string (nullable = false) - longitude of city name from city_temperatures\n",
    "    |-- AverageTemperature: float (nullable = false) - average temperature in city name from city_temperatures\n",
    "    |-- AverageTemperatureUncertainty: float (nullable = false) - average temperature uncertainty in the city name from city_temperatures\n",
    "    |-- dt: date (nullable = false) - date the temperature was recorded name from city_temperatures\n",
    "    \n",
    "## airports\n",
    "    |-- ident: string (nullable = false) - identifier for airport from airports\n",
    "    |-- name: string (nullable = false) - name of airport from airports\n",
    "    |-- State: string (nullable = false) - state the airport is located in from airports\n",
    "    |-- iata_code: string (nullable = false) - IATA code of the airport from airports --FOREGIN KEY\n",
    "    \n",
    "## us_demographics\n",
    "    |-- State: string (nullable = false) - state name of the US state from us_demographics --FOREGIN KEY\n",
    "    |-- City: string (nullable = false) - city name from us_demographics\n",
    "    |-- Median_Age: float (nullable = false) - median age in city from us_demographics\n",
    "    |-- Male_Population: integer (nullable = false) - Male population in city from us_demographics\n",
    "    |-- Female_Population: integer (nullable = false) - Female population in city from us_demographics\n",
    "    |-- Total_Population: integer (nullable = false) - Total population in city from us_demographics\n",
    "    |-- Number_of_Veterans: integer (nullable = false) - Number of veterans in city from us_demographics\n",
    "    |-- Foregin_born: integer (nullable = false) - Number of foregin born in city from us_demographics\n",
    "    |-- Average_Household_Size: float (nullable = false) - Average household size in city from us_demographics\n",
    "    |-- State_Code: string (nullable = false) - state code of city from us_demographics\n",
    "    |-- American_Indian_and_Alaska_Native: integer (nullable = false) - Count of people from native american or alskan native race in city from us_demographics\n",
    "    |-- Asian: integer (nullable = false) - Count of people from asian race in city from us_demographics\n",
    "    |-- Black_or_African_American: integer (nullable = false) - Count of people from black or afican-american race in city from us_demographics\n",
    "    |-- Hispanic_or_Latino: integer (nullable = false) - Count of people from hispanic or latino race in city from us_demographics\n",
    "    |-- White: integer (nullable = false) - Count of people from white race in city from us_demographics\n",
    "    \n",
    "## immigrations\n",
    "    |-- city_id: double (nullable = false) - Id of city from immigrations\n",
    "    |-- year: double (nullable = false) - Year the data was recorded from immigrations\n",
    "    |-- month: double (nullable = false) - Month the data was recorded from immigrations\n",
    "    |-- iata_code: string (nullable = false) - IATA code of airport from immigrations --FOREGIN KEY\n",
    "    |-- city_code: double (nullable = false) - city code from immigrations\n",
    "    |-- res_id: double (nullable = false) - id of residence from immigrations\n",
    "    |-- State: string (nullable = false) - State from immigrations\n",
    "    |-- matflag: string (nullable = false) - matchflag between arrival and departure from immigrations\n",
    "    |-- birthyear: double (nullable = false) - birthyear of passager from immigrations\n",
    "    |-- gender: string (nullable = false) - gender of the passager from immigtions\n",
    "    |-- dtaddto: string (nullable = false) - allowed days to stay from immigrations\n",
    "    |-- airline: string (nullable = false) - airline from immigrations\n",
    "    |-- visatype: string (nullable = false) - type of visa from immigrations\n",
    "    |-- visapost: string (nullable = false) - visa post from immigrations\n",
    "    |-- flight_number: string (nullable = false) - flight number from immigrations\n",
    "    |-- arrival_date: date (nullable = false) - arrival date from immigrations\n",
    "    |-- departure_date: date (nullable = false) - departure date from immigrations\n",
    "    |-- City: string (nullable = false) - city name from city_temperatures --FOREGIN KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "  - Spark is used for data processing and PostgresSQL for the model\n",
    "  - Spark was chosen because for intuitive data processing and ability to handle and process large datasets\n",
    "  - PostgreSQL was chosen because its a widely used database that allows fast queries in the intuitive SQL language\n",
    "  - We use a star schema because is allows for fast queries and still keeping the schema initive and easy to understand,\n",
    "      compard to a snowflake schema for example\n",
    "* Propose how often the data should be updated and why.\n",
    "   -  Since the data is recorded monthly, monthly updates are recommanded\n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    "     - Spark can handle the increase\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    "     - Implement a Airflow pipeline that fetches the data and displays it to the dashbord\n",
    " * The database needed to be accessed by 100+ people.\n",
    "     - The transition of the data from a local PostgreSQL database to a Cloud based option like Amazon Redshift would be recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
